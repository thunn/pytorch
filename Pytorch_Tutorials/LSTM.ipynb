{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from code by Author: Robert Guthrie\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "def convert_output(input, to_idx):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Len: 78\n"
     ]
    }
   ],
   "source": [
    "# training_data = [\n",
    "#     (\"Out of the mid-wood's twilight Into the meadow's dawn, Ivory limbed and brown-eyed, Flashes my Faun!\".split()),\n",
    "# (\"He skips through the copses singing, And his shadow dances along, And I know not which I should follow, Shadow or song!\".split()),\n",
    "#     (\"O Hunter, snare me his shadow! O Nightingale, catch me his strain! Else moonstruck with music and madness I track him in vain!\".split())]\n",
    "  \n",
    "training_data = ['I am Daniel \\n I am Sam \\n Sam I am \\n'.split(' '), 'That Sam-I-am \\n That Sam-I-am ! \\n I do not like \\n That Sam-I-am \\n'.split(' '), 'Do you like \\n Green eggs and ham \\n'.split(' '), 'I do not like them , \\n Sam-I-am . \\n I do not like \\n Green eggs and ham . \\n'.split(' '), 'Would you like them \\n Here or there ? \\n'.split(' '), 'I would not like them \\n Here or there . \\n I would not like them \\n Anywhere . \\n I do not like \\n Green eggs and ham . \\n I do not like them , \\n Sam-I-am \\n'.split(' '), 'Would you like them \\n In a house ? \\n Would you like them \\n With a mouse ? \\n'.split(' '), 'I do not like them \\n In a house . \\n I do not like them \\n With a mouse . \\n I do not like them \\n Here or there . \\n I do not like them \\n Anywhere . \\n I do not like green eggs and ham . \\n I do not like them , Sam-I-am . \\n'.split(' '), 'Would you eat them \\n In a box ? \\n Would you eat them \\n With a fox ? \\n'.split(' '), 'Not in a box . \\n Not with a fox . \\n Not in a house . \\n Not with a mouse . \\n I would not eat them here or there . \\n I would not eat them anywhere . \\n I would not eat green eggs and ham . \\n I do not like them , Sam-I-am . \\n'.split(' '), 'Would you ? Could you ? \\n In a car ? \\n Eat them ! Eat them ! \\n Here they are . \\n'.split(' '), 'I would not , \\n Could not , \\n In a car \\n'.split(' '), 'You may like them . \\n You will see . \\n You may like them \\n In a tree ? \\n'.split(' '), 'I would not , could not in a tree . \\n Not in a car ! You let me be . \\n I do not like them in a box . \\n I do not like them with a fox \\n I do not like them in a house \\n I do not like them with a mouse \\n I do not like them here or there . \\n I do not like them anywhere . \\n I do not like green eggs and ham . \\n I do not like them , Sam-I-am . \\n'.split(' '), 'A train ! A train ! \\n A train ! A train ! \\n Could you , would you \\n On a train ? \\n'.split(' '), 'Not on a train ! Not in a tree ! \\n Not in a car ! Sam ! Let me be ! \\n I would not , could not , in a box . \\n I could not , would not , with a fox . \\n I will not eat them with a mouse \\n I will not eat them in a house . \\n I will not eat them here or there . \\n I will not eat them anywhere . \\n I do not like them , Sam-I-am . \\n'.split(' '), 'Say ! \\n In the dark ? \\n Here in the dark ! \\n Would you , could you , in the dark ? \\n'.split(' '), 'I would not , could not , \\n In the dark . \\n'.split(' '), 'Would you , could you , \\n In the rain ? \\n'.split(' '), 'I would not , could not , in the rain . \\n Not in the dark . \\n Not on a train , \\n Not in a car , Not in a tree . \\n I do not like them , Sam , you see . \\n Not in a house . Not in a box . \\n Not with a mouse . Not with a fox . \\n I will not eat them here or there . \\n I do not like them anywhere ! \\n'.split(' '), 'You do not like \\n Green eggs and ham ? \\n'.split(' '), 'I do not \\n Like them , \\n Sam-I-am . \\n'.split(' '), 'Could you , would you , \\n With a goat ? \\n'.split(' '), 'I would not , \\n Could not . \\n With a goat ! \\n'.split(' '), 'Would you , could you , \\n On a boat ? \\n'.split(' '), 'I could not , would not , on a boat . \\n I will not , will not , with a goat . \\n I will not eat them in the rain . \\n I will not eat them on a train . \\n Not in the dark ! \\n Not in a tree ! \\n Not in a car ! You let me be ! \\n I do not like them in a box . \\n I do not like them with a fox . \\n I will not eat them in a house . \\n I do not like them with a mouse . \\n I do not like them here or there . \\n I do not like them anywhere ! \\n'.split(' '), 'I do not like \\n Green eggs \\n And ham ! \\n'.split(' '), 'I do not like them , \\n Sam-I-am . \\n'.split(' '), 'You do not like them . \\n So you say . \\n Try them ! Try them ! \\n And you may . \\n Try them and you may I say . \\n'.split(' '), 'Sam ! \\n If you will let me be , \\n I will try them . \\n You will see . \\n'.split(' '), 'Say ! \\n I like green eggs and ham ! \\n I do ! I like them , Sam-I-am ! \\n And I would eat them in a boat ! \\n And I would eat them with a goat ... \\n And I will eat them in the rain . \\n And in the dark \\n And on a train . \\n And in a car . \\n And in a tree . \\n They are so good so good you see ! \\n'.split(' '), 'So I will eat them in a box . \\n And I will eat them with a fox . \\n And I will eat them in a house . \\n And I will eat them with a mouse . \\n And I will eat them here and there . \\n Say ! I will eat them anywhere ! \\n'.split(' '), 'I do so like \\n Green eggs and ham ! \\n Thank you ! \\n Thank you , \\n Sam-I-am'.split(' ')]\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(training_data)\n",
    "\n",
    "#Create Indexes for each word\n",
    "word_to_ix = {}\n",
    "for sentences in training_data:\n",
    "    for word in sentences:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "ix_to_word = dict([(y, x) for (y, x) in enumerate(word_to_ix)])\n",
    "print(\"Dictionary Len:\",len(word_to_ix))\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class creation\n",
    "class LSTMPoem(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMPoem, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1900\n"
     ]
    }
   ],
   "source": [
    "model = LSTMPoem(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(word_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "inputs = prepare_sequence(training_data[0], word_to_ix)\n",
    "# print(inputs)\n",
    "\n",
    "loss_save = []\n",
    "\n",
    "for epoch in range(2000):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Variables of word indices.\n",
    "        sentence_in = prepare_sequence(sentence[0:-1], word_to_ix)\n",
    "        targets = prepare_sequence(sentence[1::], word_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(prediction, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss_save.append(loss.data)\n",
    "\n",
    "    if epoch%100 == 0: \n",
    "        clear_output()\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "# See what the scores are after training\n",
    "inputs = prepare_sequence(training_data[0], word_to_ix)\n",
    "output = model(inputs)\n",
    "# The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "#  for word i. The predicted tag is the maximum scoring tag.\n",
    "# Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "# since 0 is index of the maximum value of row 1,\n",
    "# 1 is the index of maximum value of row 2, etc.\n",
    "# Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e78b2e8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngykEREQymEJARCSDKQRERDLY/wFMltdlzs5uUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e7ecb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(loss_save)\n",
    "\n",
    "# print(np.arange(0,len(loss_save)))\n",
    "\n",
    "plt.plot(loss_save, np.arange(0,len(loss_save)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you eat them \n",
      " With a fox ? \n",
      "\n",
      "\n",
      "\n",
      " you like them \n",
      " and a goat . \n",
      " I \n",
      "\n",
      "\n",
      " will them . In not goat \n",
      " \n",
      " I do \n",
      "\n",
      "\n",
      " not you \n",
      " a . \n",
      " In In do not \n",
      "\n",
      "\n",
      " like \n",
      " In mouse ham I eggs a I . \n",
      "\n",
      "\n",
      " them Green not I \n",
      " will \n",
      " will do I \n",
      "\n",
      "\n",
      " . or . do Sam-I-am \n",
      " In in not do \n",
      "\n",
      "\n",
      " I not \n",
      " in ! I eggs a . not \n",
      "\n",
      "\n",
      " like \n",
      " With a . may \n",
      " mouse ham ! \n",
      "\n",
      "\n",
      " them Green not are ham . In I \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "text = \"Would you eat them \\n With a fox ? \\n\"\n",
    "print(text)\n",
    "\n",
    "test_seq = [text.split(' ')]\n",
    "  \n",
    "\n",
    "inputs = prepare_sequence(test_seq[0], word_to_ix)\n",
    "\n",
    "for i in range(1,10):\n",
    "    output = model(inputs)\n",
    "\n",
    "    _, indices = output.max(1)\n",
    "\n",
    "    indices = indices.data.numpy()\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    sentence = \" \"\n",
    "    for i in indices:\n",
    "        sentence = sentence + ix_to_word[i] + \" \"\n",
    "    print(sentence)\n",
    "\n",
    "    inputs = autograd.Variable(torch.from_numpy(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 7 \n",
      "-12.3275 -17.2108 -17.3332 -24.7560 -21.4880 -14.0290 -23.8857 -19.9468\n",
      "-10.8637 -14.0697  -6.7171  -7.7364  -9.9112 -15.3190  -8.3856  -8.6197\n",
      " -9.9866 -29.0834 -16.0870  -4.5366 -20.0627 -12.9711 -19.9976  -9.8210\n",
      " -9.4385 -14.5382  -5.2227  -0.5516  -7.7168 -18.4959 -12.1663  -6.1044\n",
      " -3.8543  -8.1117  -4.9169  -5.4623  -2.0584 -11.6409  -4.5103  -8.0479\n",
      " -7.2386 -13.1508 -17.5544 -25.1141 -17.3936 -11.6500 -29.4900 -13.8184\n",
      " -7.5329 -11.5568 -16.2786 -22.7537 -16.3261  -7.7401 -26.2139  -6.1446\n",
      " -7.4482 -23.2958 -16.2033 -12.7345 -18.4123 -11.4467 -26.9247  -5.2854\n",
      "-15.2413 -26.9084 -14.2957  -0.0132 -17.2023 -17.3868 -16.3916  -4.4178\n",
      " -0.9692 -11.1948 -11.1044 -18.6664 -10.5488  -2.1628  -9.4897 -12.9048\n",
      "\n",
      "Columns 8 to 15 \n",
      "-10.1249  -2.5438 -11.9714 -16.8325  -0.0858 -15.8997 -14.3794 -28.7715\n",
      "-11.9364 -15.8555  -0.3194 -15.3948  -8.0498 -18.0307 -17.7260 -15.9770\n",
      "-31.2246 -14.6222 -27.9113 -18.2094  -5.7867 -11.4419 -22.7525 -17.5006\n",
      "-16.5425 -11.9489  -9.0351 -14.3325  -7.4083 -22.4111  -8.5560  -7.1880\n",
      "-16.5492 -15.6825 -16.6253 -11.5014 -18.0825 -14.6074 -10.1369  -1.1843\n",
      "-16.7459  -9.2835 -24.7901 -14.0910  -8.2823 -13.2314  -5.8394 -16.1694\n",
      "-15.3589 -17.7995 -18.7306 -12.0878  -8.8806  -7.7856 -10.4419 -14.9248\n",
      "-29.7075 -22.3529 -24.6241 -16.9992 -10.1137 -10.2631 -16.9980 -14.8214\n",
      "-30.9151 -26.2998 -23.5182 -18.9588 -13.0729 -16.8215 -25.1824 -12.3080\n",
      "-13.5263  -9.7980 -15.3664 -11.0898  -9.1227  -1.6522 -17.2301 -16.2919\n",
      "\n",
      "Columns 16 to 23 \n",
      "-19.4847 -10.3779  -9.5868 -15.7708 -13.7201 -19.9175 -25.4857 -21.4678\n",
      "-21.9236 -19.3394  -1.8977  -7.2010 -12.7324 -13.4589 -22.0939 -24.2320\n",
      " -7.2487  -0.0317  -8.4506  -9.6144 -17.6252 -21.9187 -25.7417 -18.3799\n",
      " -9.8205 -11.8544  -2.4719  -7.3095 -16.5916 -15.2142 -16.2140 -13.7824\n",
      " -6.5164 -19.0288 -14.6675  -6.7454  -9.0556  -3.8765  -4.9001  -5.5376\n",
      " -7.8171 -11.3226 -14.5932  -9.0825 -13.3694 -16.2142 -10.7376  -9.9986\n",
      "-12.3448 -13.2570  -9.8676  -4.1000 -10.5881 -14.3455  -8.1821 -14.5948\n",
      " -9.4425  -9.2334  -5.7272  -0.5542 -16.4462 -20.2917 -19.7919 -20.1736\n",
      "-12.8755  -8.3620  -8.4415 -10.8931 -20.4959 -21.7753 -20.7399 -20.7604\n",
      "-12.0151 -13.8490 -13.0523  -4.5210  -2.7340  -4.8712 -14.0897 -13.8325\n",
      "\n",
      "Columns 24 to 31 \n",
      "-13.0586 -12.4988 -18.5671 -21.8051 -12.8164 -15.3587 -23.5523 -12.1857\n",
      " -9.1964  -7.3948 -12.9184 -13.3568 -24.9611 -16.4791 -14.0369 -14.0556\n",
      " -4.9074 -27.6773 -18.0257 -24.3866 -13.5319 -17.5777 -20.9086 -18.6900\n",
      " -8.4061 -14.3026 -11.9903 -16.3961 -13.8027 -13.6517 -13.1189 -14.7821\n",
      "-12.1853 -12.4880  -4.2431  -3.9660 -13.1756 -10.4944  -1.4262 -12.0405\n",
      " -9.9289 -21.2092 -13.4922 -20.2067  -0.0812  -5.7019 -17.3225  -6.6111\n",
      " -4.9012 -17.6394 -12.0164 -18.5884  -4.4012  -2.0998 -15.8533  -2.4114\n",
      " -0.8775 -28.3696 -16.0172 -24.2288  -9.9482  -9.8175 -19.7541 -11.1672\n",
      " -7.4450 -25.3940 -18.0403 -23.9807 -20.4103 -17.3426 -19.2285 -19.4766\n",
      " -7.3132 -10.4856  -6.6017  -5.4103 -13.4272  -9.9354  -7.0276  -7.4781\n",
      "\n",
      "Columns 32 to 39 \n",
      " -9.8229  -8.5884 -15.1164 -11.8487 -14.3263  -7.0528  -8.3380 -10.8971\n",
      "-12.1927  -2.2584 -16.4833 -14.0986 -10.2865  -5.9225  -6.5525  -8.2563\n",
      " -4.7325 -17.1575 -17.4844 -18.3104 -10.3335 -13.2691 -12.6659 -11.3369\n",
      " -9.1246  -9.2498 -13.9963 -14.7469 -10.3054  -2.4339  -2.5202  -2.7381\n",
      "-12.7954 -14.8822 -10.5698 -12.0969  -4.6947  -9.7676 -13.0534 -10.6480\n",
      "-11.4832 -22.5373  -5.9223  -6.4902 -12.0588 -11.2015 -14.0929 -12.0144\n",
      "-11.9079 -21.0262  -2.2508  -2.5721  -9.9889 -13.3418 -16.4090 -13.8289\n",
      " -9.3063 -20.1760 -10.2059 -11.1108 -11.1103 -15.0574 -15.4436 -12.1685\n",
      "-10.7889 -20.7957 -17.3389 -19.5004 -12.3808 -15.5060 -15.3948 -13.6312\n",
      " -8.4499  -8.3333  -9.5735  -7.2723  -3.0560 -12.5870 -15.8934 -14.7302\n",
      "\n",
      "Columns 40 to 47 \n",
      "-11.0442 -15.5816 -16.1709 -17.6254 -19.2796 -15.1673 -16.4104 -11.9488\n",
      " -8.5649  -9.7175 -16.7749 -12.8544 -16.5967 -13.5395 -13.4395  -9.0052\n",
      "-11.2253 -21.0923 -17.9225 -13.4611 -21.8456 -19.0861 -14.9856 -20.5823\n",
      " -2.7173 -13.1916 -13.2081 -11.4650 -12.2429 -11.4618 -14.0319  -5.3234\n",
      "-10.3889  -7.6428  -9.9910  -3.8607  -5.7160  -5.9297  -5.1460  -8.9519\n",
      "-11.4886 -21.8206  -5.4671 -11.4518  -9.1572  -7.1053 -11.3147  -8.5930\n",
      "-13.3044 -21.5569  -1.8605  -9.2277  -7.6202  -5.0254  -8.9234  -7.9456\n",
      "-11.7864 -26.2230  -9.6735 -11.7863 -16.1407 -12.6610 -12.9195 -14.4766\n",
      "-13.4443 -22.0586 -17.0758 -14.1186 -19.6301 -18.6745 -16.8441 -18.9020\n",
      "-14.7049  -7.4816 -10.7050  -4.7607 -11.5188  -7.5401  -2.8883 -14.3714\n",
      "\n",
      "Columns 48 to 55 \n",
      " -8.5394 -15.1068 -15.2644 -13.1116 -10.8206 -13.1732 -22.7054 -10.8057\n",
      " -5.0682 -11.6049 -16.1173  -7.3513  -6.4552 -15.2773 -22.7570 -11.0202\n",
      "-22.4884 -14.5960 -17.6663 -24.5382 -13.6329 -12.8318 -16.9294 -16.6986\n",
      " -7.0197  -5.1664 -13.4778 -12.7758  -4.9986  -5.6827 -16.5729 -12.8311\n",
      "-10.7709  -3.8718 -10.3688 -13.8545  -8.0789  -7.8356  -5.8233 -11.1716\n",
      "-10.2922  -9.5741  -5.9753 -23.6666 -13.9913  -5.7459  -7.7388 -13.1632\n",
      " -8.8838 -11.5221  -2.4515 -20.8635 -14.6606  -8.6017  -5.2024  -9.7213\n",
      "-14.9205 -13.6189 -10.0114 -28.3241 -15.0658 -11.6761 -12.8603 -18.3212\n",
      "-23.1178 -15.3167 -17.4817 -22.7510 -15.5341 -14.7596 -15.6962 -16.2330\n",
      " -9.8472 -10.9721  -9.8037 -12.9566  -9.8777 -14.3685  -9.8718  -8.4760\n",
      "\n",
      "Columns 56 to 63 \n",
      "-14.3566 -18.7428  -8.5550 -16.8554 -14.6461  -6.6329 -12.0593 -11.6486\n",
      "-19.9545 -11.1212  -6.7745 -14.3066 -12.2922 -18.3278 -19.3989 -18.0167\n",
      "-18.5311 -23.4911 -13.2603 -14.5044 -17.1680 -15.7947 -19.8579 -19.4510\n",
      "-16.6587 -14.4969  -5.2505 -11.3957 -13.4298 -14.8350 -23.8274 -22.3327\n",
      "-13.3901  -6.2857 -10.8926  -7.3442  -8.3237 -15.5853 -16.8445 -16.2619\n",
      " -6.1909 -20.3139 -13.1350 -10.9257 -12.9417  -3.0854 -11.2835 -11.2224\n",
      " -2.6916 -18.9648 -14.1718  -9.2712 -11.0331  -5.8266  -7.0100  -7.1625\n",
      "-14.3753 -23.9909 -14.9371 -12.4708 -15.5529 -12.8026 -18.5933 -17.8400\n",
      "-17.8932 -23.5714 -16.2054 -15.2394 -19.0324 -23.9586 -23.4477 -23.0148\n",
      "-12.1707  -6.8384 -11.0059  -8.7508  -5.8781  -8.5867  -5.2857  -5.2856\n",
      "\n",
      "Columns 64 to 71 \n",
      "-22.9450 -14.2806 -12.9832 -16.1741 -14.9019 -16.8677 -19.7929 -12.6630\n",
      "-14.1275 -15.8718 -14.7049 -10.1760 -12.2472 -11.3655 -14.6562 -13.0038\n",
      "-21.9182 -18.1940 -17.9340 -18.2192 -17.2984 -22.8634 -15.1216 -19.3144\n",
      "-12.4529 -14.3875 -13.9358 -14.2086 -14.1466  -9.5369 -12.4907 -15.9813\n",
      " -2.4445 -11.3428 -11.4479  -6.3154  -7.9661  -6.0101  -3.0201 -10.0317\n",
      "-16.8936  -5.8643  -6.1904 -16.9551 -13.2925 -10.7672 -11.2947 -12.9184\n",
      "-15.8161  -1.8516  -2.5234 -14.4431 -10.8903  -9.0820  -8.9428 -10.4700\n",
      "-20.4160 -10.2179 -10.5773 -17.9301 -15.7695 -15.9361 -12.5545 -18.6212\n",
      "-19.9212 -18.2453 -18.6020 -19.8194 -18.9901 -20.8734 -14.8993 -21.1130\n",
      " -8.9323  -9.1499  -8.4226  -3.1663  -4.9336 -10.7876  -5.4126  -5.2417\n",
      "\n",
      "Columns 72 to 77 \n",
      " -9.3869 -15.9209 -15.1720  -8.5091 -16.2795 -15.0012\n",
      " -7.9299 -14.0874 -12.7136  -8.7191 -13.3327 -12.1777\n",
      "-15.9612 -12.6022 -17.2935 -10.5343 -17.5658 -18.0982\n",
      " -8.6511 -11.4511 -13.3995  -6.0409 -10.5526 -15.5564\n",
      "-10.3369  -8.4796  -8.4671 -10.2688  -6.0552  -7.9763\n",
      "-14.9887 -10.3094 -12.8579 -12.7623 -11.3923 -14.4292\n",
      "-16.4214  -7.8604 -10.7070 -15.7306 -10.3553 -11.9382\n",
      "-18.4034 -10.6416 -15.4687 -14.5493 -16.0127 -16.9235\n",
      "-20.0358 -13.5184 -18.6255 -16.1358 -17.0496 -20.3939\n",
      " -8.3092  -8.4981  -6.6701  -9.3265  -9.5065  -3.4360\n",
      "[torch.FloatTensor of size 10x78]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wavenet]",
   "language": "python",
   "name": "conda-env-wavenet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
